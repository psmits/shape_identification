% how cryptic is cryptic diversity?
% paper describing the motivation, methods and results of the turtle
% subspecies identification project.
% journal submission order:
%   Systematic Biology (no limit)
%   American Naturalist (21 pages)
%   Journal of Evolutionary Biology

\documentclass[12pt,letterpaper]{article}\usepackage{graphicx, color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.2, 0.2, 0.2}
\newcommand{\hlnumber}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlfunctioncall}[1]{\textcolor[rgb]{0.501960784313725,0,0.329411764705882}{\textbf{#1}}}%
\newcommand{\hlstring}[1]{\textcolor[rgb]{0.6,0.6,1}{#1}}%
\newcommand{\hlkeyword}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlargument}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hlcomment}[1]{\textcolor[rgb]{0.180392156862745,0.6,0.341176470588235}{#1}}%
\newcommand{\hlroxygencomment}[1]{\textcolor[rgb]{0.43921568627451,0.47843137254902,0.701960784313725}{#1}}%
\newcommand{\hlformalargs}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hleqformalargs}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hlassignement}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlpackage}[1]{\textcolor[rgb]{0.588235294117647,0.709803921568627,0.145098039215686}{#1}}%
\newcommand{\hlslot}[1]{\textit{#1}}%
\newcommand{\hlsymbol}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlprompt}[1]{\textcolor[rgb]{0.2,0.2,0.2}{#1}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage{amsmath, amsthm}
\usepackage{graphicx, morefloats, microtype, hyperref, authblk}
\usepackage{rotating, longtable, caption, subcaption, multirow}
\usepackage[sort&compress]{natbib}
\usepackage{fullpage}

% for american naturalist
\usepackage{lineno}

\frenchspacing
\linespread{1.66}
\setlength{\parindent}{0.5in}

\setcounter{secnumdepth}{0}

%\pagestyle{empty}

\renewcommand{\section}[1]{%
\bigskip
\begin{center}
\begin{Large}
\normalfont\scshape #1
\medskip
\end{Large}
\end{center}}

\renewcommand{\subsection}[1]{%
\bigskip
\begin{center}
\begin{large}
\normalfont\itshape #1
\end{large}
\end{center}}

\renewcommand{\subsubsection}[1]{%
\vspace{2ex}
\noindent
\textit{#1.}---}

\renewcommand{\tableofcontents}{}

\bibpunct{(}{)}{;}{a}{}{,}  % this is a citation format command for natbib

% bring in various code necessities
% all the figures are made externally, so this would just be for numerics



\title{How cryptic is cryptic diversity? Machine learning approaches to classifying morphological variation in \textit{Emys marmorata} (Testudinoidea, Emydidae).}
\author[1]{Peter D Smits}%\thanks{psmits@uchicago.edu}}
\author[1,2]{Kenneth D Angielczyk}%\thanks{kangielczyk@fieldmuseum.org}}
\author[3]{James F Parham}%\thanks{jparham@fullerton.edu}}
\affil[1]{Committee on Evolutionary Biology, University of Chicago}
\affil[2]{Integrative Research Center, Field Museum of Natural History}
\affil[3]{Department of Geological Sciences, California State University -- Fullerton}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}


\begin{document}
\maketitle
\noindent{\textbf{Corresponding author:} Peter D Smits, Committee on Evolutionary Biology, University of Chicago, 1025 E. 57th Street, Culver Hall 402, Chicago, IL, 60637, USA; E-mail: \href{mailto:psmits@uchicago.edu}{psmits@uchicago.edu}}

\linenumbers
\modulolinenumbers[2]

\begin{abstract}
  Cryptic diversity is the phenomenon where some taxa are believed to be identifiable only based on molecular data. This is concerning because the majority of extant taxa and virtually all extinct taxa are delimited entirely via morphology. Here we address questions about whether it is possible to determine, based on morphology, if one classification hypotheses can be considered better than others in order to determine if possible cryptic variation is actually cryptic or just a case of extremely fine scale morphological variation. %
  Using a combination of unsupervised and supervised machine learning methods we demonstrate a suite of approaches for better understanding differences in morphology between classes, the odds of classifying one class relative to another, and what aspects of morphology best describe the differences between classes.
  %
  These approaches are applied to the classification of the emydid turtle, \textit{Emys marmorata}. This species has conflicting hypotheses of the number of meaningful subclades based on either morphological or molecular information. We compared multiple explicit classification hypotheses by characterizing variation in plastral shape and how it may be identifiably different between classes. By splitting a large dataset of specimens into both training and testing datasets, we were also able to determine which of the classification hypotheses best corresponded to the observed plastral variation in general.
  %
  The results from our analysis shows that the best classification of plastral variation in \textit{Emys marmorata} is in accordance with the molecularly based hypothesis. This demonstrates that, by using alternative methods for characterizing variability, it is possible to estimate the classification scheme which most agrees with observed variation. Additionally, we demonstrate how it is possible that not all examples of cryptic variation are truly cryptic and may just be a product of sample size or methodology because of the extremely fine scale variation between the different classes.
 
\noindent (Keywords: Testudines, Emydidae, morphology, geometric morphometrics, random forests)
\end{abstract}

%\section{Introduction}

% cryptic diversity
%   most species are still deliminated solely based on morphology
Cryptic diversity is the phenomenon that not all taxa can be recognized from morphology and can only be delimited using molecular information \citep{Stuart2006,Pfenninger2007,Funk2012,Clare2011}. Concerningly, most extant taxa, and nearly all extinct taxa, are delimited based solely via morphology. This phenomenon is of great concern when studying variation and diversity dynamics over long periods of time, where apparent morphological stasis may not actually reflect true diversity \citep{Hunt2008,Eldredge1972,Gould1977a,VanBocxlaer2013}. In the case of endangered or conserved taxa, morphometric approaches for classifying and identifying taxa and populations of importance would greatly improve the ability to maintain these high risk groups. Additionally, this could lead to better classification of extinct taxa.

Much work has been devoted to species delimitation via sequence difference \citep{Fujita2012,Yang2010b} while comparatively little has been devoted to introducing new methodology for case of purely morphological data \citep{Mitteroecker2011,Zelditch2004}. The majority of this effort has focused on identifying differences between already identified taxa \citep{Polly2007a,Demandt2009,Gaubert2005b,Gunduz2007,Polly2003,Zelditch2004} and automated taxon identification \citep{MacLeod2007}.
% all the work done on species delimitation strictly from molecular data

Here, we address the question of how can alternative approaches and methodology improve morphology based classification. From this approach, we ask if it is possible to determine which amongst a set of classification hypotheses is best in order to determine if a case of cryptic diversity is truly cryptic or just a case of extremely fine scaled morphological variation.

% past work on automatic taxon identification and older approaches to classifying taxa
% why use machine learning methods
\subsection{Background and system}
Differences in morphological variation between different classes has previously been analyzed using methods like linear discriminate analysis and canonical variates analysis \citep{Zelditch2004,Mitteroecker2011,Polly2007a,Polly2003,Gunduz2007,Gaubert2005b,Demandt2009}. These methods are comparatively straight forward ways of understanding the differences in morphology between classes. Also, they are very visual methods which aides with the interpretation and presentation of information. These previous studies, however, do not compare which amongst a set of candidate classification hypotheses is better. For example, studies such as those of \citet{Caumul2005a} and \citet{Polly2007a} focused on comparing different aspects of morphology and their fidelity to a classification scheme, instead of comparing the fidelity of one aspect of morphology to multiple classification schemes. Of note, however, is the work of \citet{Cardini2009a}, which compared morphological variation in marmots at both population, regional, and species levels to determine fidelity between shape each of these different hierarchical levels. Importantly, however, is that the classification models have not been generalized to testing data and training data accuracy is used almost exclusively as the metric off classification strength.

Here, we used multiple machine learning methods, both unsupervised and supervised, in order to compare different classification hypotheses. These methods provide different and unique advantages for understanding how to classify taxa, with what accuracy, and what these classifications are based on. While machine learning methods such as neural networks have been applied to studying shape variation \citep{MacLeod2007}, they have been primarily applied in the context of automated taxon identification and not in terms of group classification and strength of classification. Additionally, we investigate variation in continuous traits and not discrete differences between each class, instead focusing on differences in the multivariate quantification of shape.

% this paragraph kind of sucks
The two major classes of machine learning methods, unsupervised and supervised, are essentially extensions of known statistical methods \citep{Hastie2009}. Unsupervised learning methods are analogous to clustering and density estimation methods \citep{Kaufman1990}, while supervised learning methods are analogous classification and regression models \citep{Breiman1984}. In both cases, many of these methods are not fit via maximum likelihood and are supplemented by randomization, sorting, and partitioning algorithms along with the maximization or minimization of summary statistics in order to best estimate a general model for all data, both sampled and unsampled \citep{Hastie2009}. The application of the alternative approaches used in this study illustrates only a sampling of the various previously derived methods for clustering observations and fitting classification models. 
% Applications of these methods outside of this study
% epidemeology, computer science, marketing
Additionally, instead of pure classification accuracy, here we use a statistic of classification strength that reflects the rate at which taxa are both accurately and inaccurately classified (see Methods).


% e. marmorata
%   natural history
%     conservation importance (turtles in general, e. marmorata in specific)
In this study, we investiage the subspecific classification of the western pond turtle, \textit{Emys marmorata}. \textit{E. marmorata} is distributed from northern Washington State, USA to Baja California, Mexico.
%   morphological hypothesis of subspecies
%   molecular hypothesis
Traditionally, \textit{E. marmorata} was classified into three groups: the northern \textit{E. marmorata marmorata}, the southern \textit{E. marmorata palida}, and a central Californian intergrade zone \citep{Seeliger1945}. \textit{E. marmorata marmorata} is differentiated from \textit{E. marmorata palida} by the presence of a pair of triangular inguinal plates and darker neck markings. It should be noted that the triangular inguinal plates can sometimes be present in \textit{E. marmorata palida} though they are considerably smaller.

Previous work on morphological variation in \textit{E. marmorata} has focused, primarily, on differentiation between different populations within a subset of the total species range \citep{Lubcke2007,Germano2009,Germano2008,Bury2010} with comparatively little done over the entire species range \citep{Holland1992}. These studies have focused on how local biotic and abiotic factors may contribute to differences in carapace length \citep{Lubcke2007,Germano2009,Germano2008} and found that size can vary greatly between different populations. 

Additionally, there has been found a great deal of evidence for sized-based sexual dimorphism in \textit{E. marmorata} \citep{Lubcke2007,Germano2009,Holland1992} with males being on average larger than females based on total carapace length and other linear measurements. However, the quality of size as a classifier of sex can vary greatly between populations \citep{Holland1992}, which makes sense in light of the amount of between population size difference \citep{Lubcke2007,Germano2009}. However, the effect of sexual dimorphism on shape, \textit{sensu} \citet{Kendall1977a}, was not assessed \citep{Holland1992,Lubcke2007,Germano2008}.

Of particular note is the work of \citet{Holland1992} which compared morphological differences between and among many populations of \textit{E. marmorata} across the species range. \citet{Holland1992} studied the relative effect of distance versus barriers had in terms of fostering morphological differentiation in \textit{E. marmorata}. Analyses were performed to determine how different, morphologically, different populations in three different regions of the species range. Measurements were made from all different aspects of carapace morphology and not just total carapace length. 

\citet{Holland1992} concluded that distance was a poor indicator of morphological differentiation as opposed to barriers, such as different drainage basins, are probably more important barriers to reproduction. This conclusion was later echoed by \citet{Spinks2005} via molecular phylogenetic analysis. Additionally, \citet{Holland1992} found that with increasing amount of barriers and distance, morphological differentiation was observable though the underlying variation required many variables obtain indicating the very fine degree of morphological differentiation between putatively distinct populations. \citet{Holland1992} concluded that \textit{E. marmorata} is best classified as three distinct species as opposed to subspecies: a northern species, southern species, and Columbia basin species. This classification is similar to \citet{Seeliger1945}, except elevated to the species as opposed to subspecific level.

More recently, \textit{E. marmorata} was divided into four clades based on mitochondrial DNA: a northern clade, a southern clade, and eastern and western central Californian clades \citep{Spinks2005,Spinks2010}. While nuclear DNA supports two major clades, one northern and one southern, \citet{Spinks2010} argue that the four clade classification is of greater conservation utility even though the variation between these groups is considered cryptic. 
While the mitochondrially based classification is considered robust, there is no known morphological differentiation between these clades.

% central hypothesis/question of study
% statement of goals and approach
In this study, we attempt to estimate the best classification scheme of \textit{E. marmorata} based on variation in plastral shape in order to determine if the molecular based hypothesis of \citet{Spinks2005} and \citet{Spinks2010} is actually a case of cryptic diversity or not. Because of unclear geographic boundaries between subgroups of \textit{E. marmorata}, we compare two hypotheses of morphologically based classification and two hypotheses of molecularly based classification. We hypothesize that if morphological variation corresponds to class assignment, then it should be possible to determine the best classification hypothesis of \textit{E. marmorata} from amongst multiple candidate hypotheses. However, if morphological variation variation does not correspond to any classification hypothesis, then supervised learning model generalization performance will be poor and reflect how variation may not follow along with any of the candidate classification hypotheses.

\section{Materials and Methods}
\subsection{Specimens}
We collected landmark-based morphometric data from 524 adult \textit{E. marmorata} museum specimens. These specimens include both newly sampled individuals and those sampled in previous studies of plastral shape variation \citep{Angielczyk2007,Angielczyk2011,Angielczyk2013a}. 
Specimen classification was based on known specimen geographic information which was recorded from museum collection information. When precise latitude and longitude information was not available it was estimated from whatever locality information was present. Because the specimens used to define the subclades in \citet{Spinks2005} and \citet{Spinks2010} were not available for study, all specimen classifications were based solely on this geographic information and not from explicit assignment in previous studies. Instead, classification was based on matching museum locality data with the geographic boundaries of the molecularly-defined clades of \citet{Spinks2005} and \citet{Spinks2010}. Because the exact barriers between different biogeographic regions are unknown and unclear, two assignments for both the morphologically and molecularly based hypotheses were used. Each morphologically based hypothesis had three classes, while each molecular-based had four classes. In total, each specimen was given four different classifications. 

\subsection{Geometric morphometrics}
% landmarks
Following previous work on plastral variation \citep{Angielczyk2007,Angielczyk2011,Angielczyk2013a}, 19 landmarks were digitized using TpsDig 2.04 \citep{Rohlf2005}. These landmarks were chosen to maximize the description of general plastral variation(Fig. \ref{fig:plastra}). 17 of these landmarks are at the endpoints or intersection of the keratinous plastral scutes that cover the platron. 12 of these landmarks were chosen to be symmetrical across the axis of symmetry and, in order to prevent degrees of freedom and other concerns \citep{Klingenberg2002}, prior to analysis these landmarks were reflected across the axis of symmetry (i.e. midline) and the average position of each symmetrical pair was used. In cases where damage or incompleteness prevented symmetric landmarks from being determined, only the single member of the pair was used. Analysis was conducted on the resulting ``half'' plastra.
% GP superimposition and PCA
Plastral landmark configurations were superimposed using generalized Procrustes analysis \citep{Dryden1998a} after which, the principal components (PC) of shape were calculated. This was done using the \texttt{shapes} package for R \citep{2013,Dryden2013}.


\subsection{Machine learning analyses}
\subsubsection{Unsupervised learning}
% clustering
%   Riemannian shape distance
In order to preserve the relationship between all landmark configurations in shape space, the dissimilarity between observations was measured using Kendall's Riemanninan shape distance or \(\rho\) \citep{Kendall1984a,Dryden1998a}. This metric was chosen because shape space, or the set of all possible shape configurations following Procrustes superimposition, is a Riemannian manifold and thus non-Euclidean \citep{Dryden1998a}. \(\rho\) varies between 0 and \(\pi / 2\) when there is no reflection invariance, which should not be a concern in the case of the half plastral landmark configurations used in the study.

%   PAM
The \(\rho\) dissimilarity matrix was divisively clustered using partitioning around mediods clustering (PAM), a method similar to \textit{k}-means clustering except that instead of minimizing the sum of squared Euclidean distances between observations and centroids, the sum of squared dissimilarities between observations and mediods is minimized \citep{Kaufman1990}.
%   gap statistic
Because the optimal number of clusters of shape configurations in the study was unknown, being possibly three, four, or some other value, clustering solutions were estimated with the number of clusters varied between one and 40. Clustering solutions were compared using the gap statistic, which is a measure of goodness of clustering \citep{Tibshirani2001a}. The gap statistic is defined
\[Gap_{n}(k) = E^{*}_{n}[\log(W_{k})] - \log(W_{k})\] 
where \(W_{k}\) is
\[W_{k} = \sum^{k}_{r = 1}{\frac{1}{2n_{r}} (\sum_{i,i' \in C_{r}} d_{ii'})}\].
\(d_{ii'}\) is the dispersion of the clustering solution or the sum of the pairwise dissimilarities between observations in each cluster and their respective mediods (\(C\)) for all clusters \(r\). This value is averaged and compared to the expected dispersion (\(E^{*}_{n}\)) of a sample \(n\) from a reference distribution. In this case, the reference distribution was estimated from 500 resamples of the dataset while maintaining the original dispersion of the data.
%  R implementation
This analysis was conducted using the \texttt{cluster} package for R \citep{Maechler2013} using all 524 observations.

\subsubsection{Supervised learning}
% training testing split
The total dataset of 524 observations was split into training and testing datasets. The training dataset represented 75\% of the total dataset, split proportionally by class, and was used for model fitting. The testing dataset represented the remaining 25\% of the total dataset and  was used after model fitting to estimate the effectiveness of each classification hypothesis and generalizability of the supervised learning models (i.e. performance in the wild). This split was chosen to allow for a large enough sample size for model fitting while also providing a large enough testing dataset to determine any systematic misclassifcations.

% model types
Three different supervised learning methods were used to model the relationship between plastral shape and class: linear discriminate analysis, multinomial logistic regression and random forest. These methods were chosen because of various properties of these methods which allow for useful interpretations about the quality and structure of the classification.

% linear discriminate analysis
Linear discriminate analysis (LDA) is a frequently applied method for characterizing the primary differences in morphology between different classes \citep{Zelditch2004,Mitteroecker2011}. This method attempts to find a linear combination of predictors to best model two or more classes. LDA is very similar to PCA except that instead of finding the linear combination of features that maximize the amount of explained variance in the data, LDA maximizes the differences between classes. The results of this analysis produces a transformation matrix by which the original features can be transformed to reflect the best discrimination between the classes. Like other supervised learning methods, LDA can also be used for predictive analysis on testing data. LDA was done using the \texttt{MASS} package for R \citep{Venables2002a}.

%   multinomial logistic regression
Multinomial logistic regression is an extension of logistic regression, where instead of a binary response there are three or more response classes \citep{Venables2002a}. Effectively, this type of model can be viewed as multiple, simultaneous logistic regression models for each class and the final classification of the observation being the most probable of all the constituent model results. Similar to the odds ratios calculated from the coefficients of a logistic regression, the relative risk of a classification with reference to a baseline class can be determined from the coefficients of the model. Multinomial logistic regression models were fit using the \texttt{nnet} package for R \citep{Venables2002a}

%   random forest
Random forest models are an extension of classification and regression trees (CART) \citep{Breiman1984,Breiman2001}. Because this study relies on classification models, CARTs are explained with reference to classification but the approach is equally valid for regression. The goal of CARTs are to use a series of different features to estimate the final class. In top-down induction of decision trees for each member of a given set of predictor variables, attribute value test are used to estimate the differences between classes. This process is then repeated on each subset, called recursive partitioning. The recursion continues until the resulting observations all share the same class or no more meaningful partitions are possible. The resulting model is a tree structure by which observations are classified at each intersection via the estimated cutoff points from the attribute tests made during model fitting.

In a random forest model, many CARTs are built from a random subsample of both the features and the observations. This process is then repeated many times and the parameters of the final model was chosen as the mode of estimates from the distribution of CARTs \citep{Breiman2001}. In addition to fitting a classification model, this procedure allows for the features to be ranked in order of importance. In the context of this study, this means that the PCs most important for describing the difference between classes can be estimated, and thus illustrate the most important variation amongst classes as opposed to just the greatest amount of variation in the entire dataset. This is a generally important property that is useful for many other studies which want to describe and model the differences between classes and the relative importance different features. Random forest models were fit using the \texttt{randomForest} package for R \citep{Liaw2002}.
%   R statement


% model training
%   tuning parameters
%     grid search
%       what are the tuning parameters for each model?
%     best AUC
The supervised learning models used here, except LDA, have tuning parameters which help to increase the genearlizability of the model and prevent them from being overfit. For the supervised learning models fit in this study, tuning parameters were estimated via 10 rounds of 10-fold cross-validation (CV) across a grid search of all tuning parameter combinations. Optimal tuning parameter values were selected based on area under the receiver operating characteristic (ROC) curve. The area under the multiclass ROC curves was estimated using the all-against one strategy derived by \citet{Hand2001}. This tuning process was implemented following the default grid search implemented in the \texttt{caret} package for R \citep{Kuhn2013}.

% what is ROC? what is AUC?

ROC is a confusion matrix (Table \ref{tab:conf}) statistic that is a descriptor the relationship between the false positive rate (\(FPR\), Eq. \ref{eq:fpr}) of a classification model and the true positive rate (\(TPR\), Eq. \ref{eq:tpr}) of a classification model \citep{Hastie2009}. 
The area under the ROC curve (AUC) is a summary statistic of the quality of the classification and varies between 0.5 and 1, with values of 0.5 indicating a model that classifies no better than random and a value of 1 indicating perfect classification \citep{Hastie2009}. AUC can be used as a model selection criterion for classification models and is especially useful in cases where some if not all of the models in question were not fit via maximum likelihood where a criterion such as AICc (see below) or similar can be used \citep{Hastie2009}. It is important to note that, unlike AICc, AUC is not calculated with reference to the complexity of the model.

\begin{equation}
  FPR = \frac{FP}{FP + TN}
  \label{eq:fpr}
\end{equation}
\begin{equation}
  TPR = \frac{TP}{TP + FN}
  \label{eq:tpr}
\end{equation}

%   model selection
%   LDA
LDA was applied on the eigenscores from a subset of the total number of PCs, ranging from two to 10 in increasing order of complexity. In total, this produced nine different LDA scaling matrices. From this set, the best number of PCs used to estimate the LDA scaling matrix were chosen. As LDA is not ``fit'' via maximum liklihood, the final combination of number of PCs and LDA scaling matrix chosen was that with the greatest AUC value from the training set.

%     AICc
For the multinomial logistic regression models, 10 different models were fit each having sequentially more PCs as predictors in order to have models representing different levels of overall amount of shape variation and to estimate how much was necessary and sufficient to best estimate class. The maximum number of PCs allowed as predictors was 10 because of both the large number of parameters estimated per model and the necessary sample size needed to estimate that many parameters accurately. The final model was that with the lowest AICc \citep{Akaike1974,Hurvich1989,Burnham2002a}. AICc is a model selection criterion where the model with lowest AICc has the fairest variance--bias tradeoff \citep{Burnham2002a}. Model selection was performed in this manner because the optimal number of PCs to use as predictors was not know \textit{a priori}, and while including all of the PCs of shape would mean that all shape variability would be used to estimate class, this may cause the model to be overfit and not provide an accurate estimate of unsampled plastral variation. In addition to the AICc of each model the \(\Delta\)AICc and Akaike weights are also reported. \(\Delta\)AICc values are the different in AICc between the AICc best model and that model while Akaike weights are a transformation of the AICc of a model with relation to all other models being compared and measures the relative amount of information explained by that model compared to all other models \citep{Burnham2002a}. 

%     recursive feature selection
Random forest models are not fit using maximum likelihood so AICc based model selection was not possible. Instead, a recursive feature selection algorithm was used to choose the optimal number of PCs to include based on the AUC of the model. Following the backwards selection algorithm implemented in \texttt{caret} \citep{Kuhn2013}, the maximum number of features were included in the initial model, their importance ranked, and the AUC of the model calculated. The lowest ranked feature was then removed, and the AUC of the model recalculated. This was repeated until only one feature, remained. Similar to the multinomial logistic regression models described above, the maximum number of PCs that could have been included in the model was 10. After each PC was removed , 10-fold CV was used to estimate the optimal values of the tuning parameters as well as quantify the uncertainty of each model. Random forest model parameters were estimated from 1000 subtrees. Because PCs were kept in order of importance and not in relation to the amount of variance each PC described, this means that the exact PCs included in each model do not correspond to the PCs in each of the 10 multinomial logistic regressions models.

% generalization
%   bootstrap resample of AUC
The final selected models were then used to estimate the class assignments of the training dataset. Model generality for both methods for all four classification schemes was measured using the AUC of the assignments. A distribution of AUC values was estimated for each classification scheme via 1000 nonparametric bootstrap resamples of the training dataset. The difference in distributions was assessed using pairwise Mann-Whitney U tests.

\section{Results}
\subsection{Geometric morphometrics}
The results of the PCA of the total dataset of \textit{E. marmorata} pastral landmarks configurations demonstrates no clear or obvious groupings (Fig. \ref{fig:pca}). The first three PCs, which represent 45.29\% of the total variation, are a cloud of points with no structure. Additionally, individual landmark variation is mostly circular around each landmark with some more elliptical variation observed along some midline landmarks and the most lateral landmark (Fig. \ref{fig:pca}). However, it is important to note that Procustes based superimposition attempts to evenly distribute variance around the mean shape \citep{Zelditch2004} and this observation should be considered cursory at best.

The first two PCs appear to describe principally variation in the lateral margin of the palstra, from a pointed medial edge to a more rounded and blunt edge (Fig. \ref{fig:pc_var}). Landmark 10 (Fig. \ref{fig:plastra}), which appears to be the most variable along these axes (Fig. \ref{fig:pca} and \ref{fig:pc_var}), is positioned on the bridge between the plastron and the carapace. Over ontogeny, this is an area that deepens dorsoventrally and when the plastron was projected into two dimensions it created the effect of mediolateral movement.
Lateral landmark variation along the first PC seemed concentrated in the posterior portion of the plastra with additional variance observed in midline landmarks (Fig. \ref{fig:pc_var}). This variance in midline landmarks was most likely caused by the fact that plastral scutes frequently do not line up perfectly. Along PC 2, lateral variation appeared to be concentrated in the anterior portion o the plastra (Fig. \ref{fig:pc_var}).

% size correlation with either of the first two PCs?


\subsection{Machine learning analyses}
\subsubsection{Unsupervised learning}

% PAM results
Comparison of gap statistic values for the range of PAM solutions indicates that the optimal number of clusters is one (Fig. \ref{fig:gap}). The next best clustering solution had only two clusters, however there is no geographic structure to this classification scheme, with members of these clusters being seemingly randomly distributed (Fig. \ref{fig:gap_map}). Importantly, these clusters do not conform to the northern and southern groups from the nuclear DNA hypothesis \citep{Spinks2010}.

% some sex information. Analyze it.
Sex information was only avaliable for 399 of the 524 turtles. A \(\chi^{2}\) test of the relationship between sex observation and cluster assignment from PAM with two clusters showed that there was no significant relationship between cluster assignment and sex observation (\(\chi^{2}\): 1.12, df: 1, \textit{p}-value: 0.29, Table \ref{tab:chi}). This results is interesting because while sexual dimorphism has been observed in linear measures and mass estimates of \textit{E. marmorata} \citep{Lubcke2007,Germano2009,Holland1992}, this results demonstrates that this dimorphism may not translate into differences in shape. Interestsingly, male emydid turtles are known to have a plastral concavity which may influence landmark position along the midline. However, the plastral concavity of \textit{E. mamorata} males is considered less pronounced than in other emydid turtles.


The gap statistic values for both three and four clusters are much lower than for one and two and are statistically identical. Interestingly, other solutions with a much greater number of clusters have relatively high gap statistic values as well though these are also not significantly different. Increasing the number of clusters does appear to improve the gap statistic enough compared to the best clustering solution to merit detailed discussion.

% figure
%   gap statistic results

\subsubsection{Supervised learning}
%For all of the classification schemes, the optimal models for both the multinomial logistic regression (Table SUPPLEMENT) and random forest (Fig. \ref{fig:roc}) methods include many, if not most, of the possible features.


The optimal number of PCs used for LDA, as determined by highest ROC score, for three of the four classification schemes had all 10 possible PCs (Fig. \ref{fig:roc}). These were both of the morphological based classification hypotheses and the second molecular hypothesis. LDA of the PCs of the first molecular hypothesis found that, based on ROC, only the first 9 PCs were necessary to best discriminate between the classes (Fig. \ref{fig:roc}). The first 9 PCs describe 83.23\% of total variation in plastral shape, while the first 10 PCs describe 86.54\% of the variation.




% multinomial logistic regression model
The AICc best multinomial logistic regression model for three of the four classification schemes had the first 9 PCs as features (Tables \ref{tab:mod_sel_1}, \ref{tab:mod_sel_2}, and \ref{tab:mod_sel_3}). The second molecularly based classification hypothesis included all 10 possible PCs as predictors (Tables \ref{tab:mod_sel_4}).
The \(\Delta\)AICc values between the optimal and second best model range from 1.18 for the first morphological based classification hypothesis to 26.51 for the second molecular based classification hypothesis (Tables \ref{tab:mod_sel_1}, \ref{tab:mod_sel_2}, \ref{tab:mod_sel_3}, and \ref{tab:mod_sel_4}).

While the \(\Delta\)AICc value between the optimal and second best model for the first morphological and first molecular based classification hypothesis was within the range to be considered equally optimal \citep{Burnham2002a}, for this analysis we chose to use only the AICc best model. While AICc values can not be compared between models with different responses \citep{Burnham2002a}, we interpret the fact that the \(\Delta\)AICc best model in these cases is the simpler model and that the optimal model for three of the classification schemes having the same number of predictors as reasons to use only the AICc best model for all cases. 
Additionally, by using a single model for each of the classification hypotheses, this limits the number of comparisons between the bootstrap resampled distributions of the AUC values for the testing dataset (see below).

% random forest model



The selected number of features in the final random forest model for each classification scheme was very simpler to the model selection results for the LDA-based classification and the multinomial logistic regression models, ranging from 9 for the second morphological based classification hypothesis and both molecular based classification hypotheses to 10 for the first morphological based classification hypothesis (Fig. \ref{fig:roc}). 

% need to discuss the final models in both cases.
% figure
%   ROC model selection (see talk)
%   generalize densities
%     facet: multinomial, rf (see talk)

In the case of all models, there is a substantial increase in model performance as measured by AICc for the multinomial logistic models (Tables \ref{tab:mod_sel_1}, \ref{tab:mod_sel_2}, \ref{tab:mod_sel_3}, and \ref{tab:mod_sel_4}) or in AUC for the LDA-based predictions and random forest models and illustrated for the multinomial logistic regression models as the number of features increases (Fig. \ref{fig:roc}). 

The results from the generalization of the selected supervised learning models, measured by the distributions of the bootstrapped AUC values of the testing dataset, show that a molecular classification hypotheses was the best overall classification scheme (Fig. \ref{fig:gen_res}). Remarkably, the best classification hypothesis was the second molecular classification hypothesis based on the LDA-based predictions, the multinomial logistic regression and random forest models. For both methods, the distribution of bootstrapped AUC for the molecular hypothesis was significantly greater than all of the other classification schemes (Tables \ref{tab:lda_test}, \ref{tab:mm_test} and \ref{tab:rf_test}). 


When the classification results of the training set for the best classification scheme based on the generalization results are compared with the references classes, the higher AUC value of the best results from LDA and the best multinomial logistic regression model compared to the best random forest model can be observed as the classifications are much closer to the reference classes (Fig. \ref{fig:gen_map}). The best random forest model misclassified many of the observations as the northern clade instead of the correct class. This pattern of misclassification is observable but not as exaggerated in the LDA-based classifications and those from the multinomial logistic regression model (Fig. \ref{fig:gen_map}).

This pattern of misclassification may have been caused by the subtle differences in mean shape between each of the different classes (Fig. \ref{fig:mean_shape}). The mean shape of the northern clade is the most similar to the mean shape of the entire dataset (Fig. \ref{fig:mean_shape1}), which may indicate that specimens that are closer to the mean shape will be systematically misclassified as the northern clade.

% variation along the most important axes


The results of fitting the final random forest model also include the variable importance for best separating the different classes. The selected random forest model for the best classification scheme had 9 PCs as features. The PCs included as features in the final random forest model, in descending order of importance, were PCs 3, 2, 1, 6, 5, 10, 9, 8 and 4. Of these 9 features, the first three are illustrated here (Fig. \ref{fig:imp_pc}) in descending order of importance. 


The first two most important features describe different aspects of variation (Fig. \ref{fig:imp_var}). The third and most important PC describes variation roundedness of the medial portion of the plastron, both the anterior and posterior portions of the plastron. Additionally, the relative position of the landmarks along the midline varies greatly along PC3 (Fig. \ref{fig:imp_var}). This PC represents 12.19\% of total variation. The second and second most important PC is described above and principally described variation in landmarks along the lateral and anterior margin of the plastron. This PC represents 12.78\% of total variation. The major variations along these axes correspond well to the differences between the mean shape of each class (Fig. \ref{fig:mean_shape}) where major class differences seem based on the relative ballooning or shrinking of the anterior and posterior portions of the plastron together along with differential ``pinching'' of the midline landmarks.

The relative risk values for classification from the multinomial logistic regression model, based on the three most important PCs, demonstrate that individual axes contribute to classification differently and that given multiple features the odds of determining the correct classification increase (Fig. \ref{fig:rel_risk}). The first most important axis contributes strongly to classifying both the western and southern groups while changes along the second most important axes contribute very little to increasing the odds of classification for all but the eastern group. This is observable from the class histograms of PC 3 and 2 (Fig. \ref{fig:imp_var}). Changes along the first and third most important axes contribute more obviously to increasing the odds of correctly identifying the class of an observation, a result that is observable in both the relative risk (Fig. \ref{fig:rel_risk}) and the different class histograms of the PCs (Fig. \ref{fig:imp_var}).

The graphical results from the LDA of the training dataset for models of the second molecular classification scheme agree with the subtle distinctions between the different classes (Fig. \ref{fig:lda}). There is no clear distinction in terms of multivariate space between the four different classes. Instead, across all three axes there is substantial overlap as indicated by both the scatter of the points in space and the distribution of observations along each axis.

\section{Discussion}
% discussion of results
%   remarkable concordance in the supervised learning methods
The results of this study support the mitochrondial based classification hypothesis of \textit{E. marmorata} \citep{Spinks2005,Spinks2010}. This is contrary to the original classification of \textit{E. marmorata} \citep{Seeliger1945,Holland1992} and lends credence to the idea that at least some aspect of cryptic diversity is a product of sample size, methodology, or both.

%   what does this mean about cryptic diversity?
%   unsupervised learning shortcomings

The lack of coherent geographical subclass assignment from PAM clustering (Fig. \ref{fig:gap}) as well as the large number of features necessary before no increase in AUC for all models (Fig. \ref{fig:roc}) indicates that the morphological variation between classes is extremely fine grained. This was also exemplified by the small differences between mean class shapes of the final chosen classification scheme (Fig. \ref{fig:imp_var}).

% methodological concerns
%   compromise in the supervised learning models
%     fair because as much variation as ``necessary'' is used
The approaches presented here for supervised learning analysis of the landmark variation represent a compromise between explicitly modeling all shape variation and preventing models from being overfit and ungeneralizable. While all aspects of shape may be evolving simultaneously, and not along individual PCs, including all shape variation in each model might increase model complexity beyond a reasonable level for the sample size and possibly the necessary complexity to accurately model the response. Additionally, because only individual PCs are used as features in the models, this does not accurately represent shape evolution and how exactly different classes might be evolving in relation to each other. However, this compromise is not without its advantages. Because both AICc and AUC values improved rapidly with increased model complexity (Fig. \ref{fig:roc}), this helped demonstrate how fine scale the actual variation between classes was. The variable importance information from the random forest models was extremely useful for understanding what aspects shape variance contributed most to differentiating the classes and in what order as opposed purely in the order of largest variance (Fig. \ref{fig:imp_pc} and \ref{fig:imp_var}). Additionally, the relative risk values from the mulitinomial logistic regression models demonstrate that a single PC is probably not sufficient for estimating the class of an observation, but that given a set of PCs this classification would be more accurate (Fig. \ref{fig:rel_risk}).

%   unsupervised learning
Ultimately, it would be useful to not require such explicit classification hypotheses, especially when concerned about possible cryptic variation in extinct taxa. The only unsupervised method employed in this study, PAM, is rather simple and not model based. A more useful approach would be to employ various model based clustering approaches \citep{Fraley2002,Zhong2003,VanBocxlaer2013}. In this manner, a series of candidate models can be compared via model comparison methods, such as AIC or Bayes factors \citep{Fraley2002}, in order to asses the best clustering solution. % beat complaints from reviewers
Here we focused on the results and utility of supervised methods because they are both more powerful and hypothesis driven \citep{Hastie2009}. Because there are two alternative classification schemes for \textit{E. marmorata}, it was most appropriate to compare these two hypotheses and estimate which one most accurately reflected the variation. Future work would be to explore and derive unsupervised methods which corroborate these results.

% closing statements
In this study we have demonstrated that, using alternative methodology to that which is most frequently applied, it is possible to determine which classification scheme best matches variation in a taxon amongst a set of alternative hypotheses. The observed plastral variation of \textit{E. marmorata} is most consistent with the mitochondrial based hypothesis of \citet{Spinks2005} and \citet{Spinks2010} and not with the original morphology based hypothesis of \citet{Seeliger1945,Holland1992}. We have also demonstrated the utility of various machine learning approaches to understanding the structure of variation in morphometric data. Specifically, methods for better understanding misclassification and identifying which is the most important for delimiting different classes. These methods represent new applications which may be important for future studies on class-based morphological comparison and variation, both in the context of cryptic diversity and with known classifications.

\section{Acknowledgements}
PDS would like to thank David Bapst, Michael Foote, Benjamin Frable, and Dallas Krentzel for useful discussion which enhanced the quality of this study. For access to emydine specimens, we thank: J. Vindum and R. Drewes (CAS); A. Resetar (FMNH); R. Feeney (LACM); C. Austin (LSUMNS); S. Sweet (MSE); J. McGuire and C. Conroy (MVZ); A. Wynn (NMNH); P. Collins (SBMNH); B. Hollingsworth (SDMNH); C. Bell and R. Burroughs (TMM); T. LaDuc and R. Burroughs (TNHC); P. Holroyd (UCMP); R. Symonds (UMZC); J. Buskirk. We are greatful to S. Sweet for field assistance and the California Department of Fish and Game for permits. Much of the data collection was funded by NSF DBI-0306158 (to KDA).

\bibliographystyle{sysbio}
\bibliography{turtle,packages}

\pagebreak

% figures
\begin{figure}[ht]
  \centering
  \includegraphics{figure/plastra}
  \caption{Depiction of general plastral shape of \textit{E. marmorata} and position of the 19 landmark used in this study. Anterior is towards the top of the figure.}
  \label{fig:plastra}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width = \textwidth]{figure/pca_res}
  \caption{Results from PCA of the Procrustes superimposed ``half'' plastral landmarks. Depicted here are the for three PCs (lower triangle) and the mean shape with observed variance around each point (upper right). The first three PCs account for total 45.2924805932624\% of the variance in plastral shape.}
  \label{fig:pca}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width = \textwidth]{figure/pc_var}
  \caption{Landmark variation along the first two PCs of the Procrustes superimposed ``half'' plastral landmarks. The first row corresponds to variation along the first PC, while the second row corresponds to the second PC. The left most column represents the observation with the highest eigenscore along that PC, while the right most column represents the observation with the lowest eigenscore. The middle column, for both rows, is the mean plastral shape for all observations. The first PC represents 20.32\% of the total variation in plastral shape while PC represents 12.78\% of the variance.}
  \label{fig:pc_var}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width = \textwidth]{figure/gap_res}
  \caption{Gap statistic values for PAM clustering results for the \(\rho\) dissimliarity matrix of plastron shape. Error bars are standard errors estimated via 500 bootstrap samples.}
  \label{fig:gap}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics{figure/gap_map}
  \caption{Clustering solution for PAM with two mediods for the entire set of observed \textit{E. marmorata}. Clustering was based entirely on the \(\rho\) dissimilarity matrix of ``half'' plastral landmark configurations following Procrustes superimposition.}
  \label{fig:gap_map}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width = \textwidth]{figure/roc_sel}
  \caption{Effect of increasing the number of PCs as features, or predictors, of classification of plastra for all four classification schemes. As the total number of features increase, AUC increases until eventually leveling off. LDA-based classification, multinomial logisitic regression and random forest models are illustrated here, though AUC based model selection was only performed for the LDA-based classification and the random forest models.}
  \label{fig:roc}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width = \textwidth]{figure/gen_res}
  \caption{Density estimates of AUC values of predictions of the testing dataset of plastra from 1000 bootstrap resamples. The top facet corresponds to values using the best LDA-based classifications of the eigenscores of shape, as chosen by maximum AUC. The middle facet corresponds to values using the optimal multinomial logistic regression model, as chosen by minimum AICc value. The bottom facet corresponds to the values using the optimal random forest model, as chosen by maximum AUC value.}
  \label{fig:gen_res}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width = \textwidth]{figure/gen_map}
  \caption{Comparison between reference classification of testing data set (upper left) and the estimated classifications based on the selected LDA-based classification (lda, upper right), multinomial logistic regression (multi, lower left) and random forest models (rf, lower right). Classification corresponds to the four classes as suggested by the hypothesis of \citet{Spinks2005} and \citet{Spinks2010}.}
  \label{fig:gen_map}
\end{figure}

% mean shapes of all the classes
\begin{figure}[ht]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[width = \textwidth]{figure/mshape_1}
    \caption{Northern}
    \label{fig:mean_shape1}
  \end{subfigure}
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[width = \textwidth]{figure/mshape_2}
    \caption{Eastern}
    \label{fig:mean_shape2}
  \end{subfigure}
  % new line. might want to make these closer together

  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[width = \textwidth]{figure/mshape_3}
    \caption{Western}
    \label{fig:mean_shape3}
  \end{subfigure}
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[width = \textwidth]{figure/mshape_4}
    \caption{Southern}
    \label{fig:mean_shape4}
  \end{subfigure}
  \caption{Thin-plate splines for each of the four classes from the best classification hypothesis based on the generalization results (Fig. \ref{fig:gen_res}). The four different classes are labeled according to the biogeographic groups as depicted in figure \ref{fig:gen_map}. The deformations are depicted with 2x magnification from base.}
  \label{fig:mean_shape}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width = \textwidth]{figure/pca_imp}
  \caption{Pairs plot of the first three most important variables of the optimal random forest model of turtle plastral shape. The variables descend in importance from the upper left to the lower right. The observations are colored as in figure \ref{fig:gen_map}.  The bottom row are histograms of classification occurrences along the PCs.}
  \label{fig:imp_pc}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width = \textwidth]{figure/imp_var}
  \caption{Landmark variation along the two most important features (PCs) based on the final random forest model. The first row corresponds to the third PC and the second corresponds to the second PC. Landmark configurations are minimum observed on that PC, mean shape, and maximum observed on that PC.}
  \label{fig:imp_var}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width = \textwidth]{figure/rel_risk}
  \caption{Forest plot of the relative risk, with 95\% confidence intervals, of classifying a give specimen based on the first three most important variables according to the random forest model. Relative risk values are calculated from the coefficients of the multinomial logistic regression model. All risks are relative to the northern group from \citet{Spinks2005,Spinks2010}. Variable importance is from left to right.}
  \label{fig:rel_risk}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width = \textwidth]{figure/lda}
  \caption{Pairs plots of the three discriminate axes from the linear discriminate analysis of the eigenscores from the first 10 PCs of plastral shape. The observations figured are from from the training data set used for all models for the second molecular classification hypothesis based on \citet{Spinks2005} and \citet{Spinks2010}. Observations are colored as in Fig. \ref{fig:gen_map}.}
  \label{fig:lda}
\end{figure}


\pagebreak
% tables
\begin{table}
  \centering
  \begin{tabular}[c]{ p{2cm} c | p{2cm} | p{2cm} |}
    \cline{3-4} 
    & & \multicolumn{2}{ c |}{Predicted class} \\ \cline{3-4}
    & & 1 & 0 \\ \hline
    \multicolumn{1}{| c |}{\multirow{2}{*}{Actual class}}
    & 1 & TRUE \newline POSITIVE & FALSE \newline NEGATIVE \\ \cline{2-4}
    \multicolumn{1}{| c |}{} & 0 & FALSE \newline POSITIVE & TRUE \newline NEGATIVE \\
    \hline
  \end{tabular}
  \caption{Example confusion matrix. The columns correspond to the predicted class of an observation, while the rows correspond to the actual class of that observation. Depending on the type match between the prediction and reality, four different outcomes are possible: true positive (TP), false negative (FN), false positive (FP), and true negative (TN). These four quantities are used for calculating all confusion matrix statistics. Each of these values is an integer and the sum of the number of occurrences of that event during classification.}
  \label{tab:conf}
\end{table}

\begin{table}
  \centering
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Sat Aug 10 22:49:42 2013
\begin{tabular}{r|cc|c}
  & F & M & tot \\ 
  \hline
1 & 101 & 112 & 213 \\ 
  2 & 99 & 87 & 186 \\ 
   \hline
tot & 200 & 199 & 399 \\ 
  \end{tabular}


  \caption{Tabular comparison between sex observation and cluster assignement from PAM with two clusters. This number of clusters was chosen because it represented the second best clustering solution as determined via gap statistic comparison (Fig. \ref{fig:gap}). \(\chi^{2}\) analysis of this contigency table showed that there is no relationship between sex observation and cluster assignment (\(\chi^{2}\): 1.12, df: 1, \textit{p}-value: 0.29).}
  \label{tab:chi}
\end{table}

\begin{sidewaystable}
  \centering
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Sat Aug 10 22:49:42 2013
{\small
\begin{tabular}{lllllllllllrrrrr}
  \hline
(Intercept) & PC1 & PC2 & PC3 & PC4 & PC5 & PC6 & PC7 & PC8 & PC9 & PC10 & df & logLik & AICc & delta & weight \\ 
  \hline
+ & + & + & + & + & + & + & + & + & + &  & 20.00 & -250.00 & 542.26 & 0.00 & 0.64 \\ 
  + & + & + & + & + & + & + & + & + & + & + & 22.00 & -248.35 & 543.43 & 1.18 & 0.36 \\ 
  + & + & + & + & + & + & + & + &  &  &  & 16.00 & -261.94 & 557.33 & 15.07 & 0.00 \\ 
  + & + & + & + & + & + & + & + & + &  &  & 18.00 & -259.99 & 557.82 & 15.56 & 0.00 \\ 
  + & + & + & + & + & + & + &  &  &  &  & 14.00 & -275.68 & 580.48 & 38.22 & 0.00 \\ 
  + & + & + & + & + & + &  &  &  &  &  & 12.00 & -281.10 & 587.03 & 44.77 & 0.00 \\ 
  + & + & + & + & + &  &  &  &  &  &  & 10.00 & -305.55 & 631.68 & 89.43 & 0.00 \\ 
  + & + & + & + &  &  &  &  &  &  &  & 8.00 & -318.48 & 653.34 & 111.09 & 0.00 \\ 
  + & + & + &  &  &  &  &  &  &  &  & 6.00 & -344.14 & 700.49 & 158.24 & 0.00 \\ 
  + & + &  &  &  &  &  &  &  &  &  & 4.00 & -346.80 & 701.71 & 159.45 & 0.00 \\ 
   \hline
\end{tabular}
}


  \caption{Model selection table for the multinomial logistic regression models of the first morphologically based classification hypothesis. This classification hypothesis corresponds to ``morph 1'' also depicted in figures \ref{fig:roc} and \ref{fig:gen_res}. This hypothesis is based on \citet{Seeliger1945}. The column ``delta'' corresponds to the \(\Delta\)AICc values of each model, while ``weights'' correspond to the Akaike weight of that model relative to all others.}
  \label{tab:mod_sel_1}
\end{sidewaystable}

\begin{sidewaystable}
  \centering
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Sat Aug 10 22:49:42 2013
{\small
\begin{tabular}{lllllllllllrrrrr}
  \hline
(Intercept) & PC1 & PC2 & PC3 & PC4 & PC5 & PC6 & PC7 & PC8 & PC9 & PC10 & df & logLik & AICc & delta & weight \\ 
  \hline
+ & + & + & + & + & + & + & + & + & + &  & 20.00 & -245.15 & 532.56 & 0.00 & 0.83 \\ 
  + & + & + & + & + & + & + & + & + & + & + & 22.00 & -244.53 & 535.79 & 3.23 & 0.17 \\ 
  + & + & + & + & + & + & + & + & + &  &  & 18.00 & -254.69 & 547.21 & 14.64 & 0.00 \\ 
  + & + & + & + & + & + & + & + &  &  &  & 16.00 & -258.00 & 549.45 & 16.88 & 0.00 \\ 
  + & + & + & + & + & + & + &  &  &  &  & 14.00 & -268.69 & 566.49 & 33.93 & 0.00 \\ 
  + & + & + & + & + & + &  &  &  &  &  & 12.00 & -271.30 & 567.42 & 34.86 & 0.00 \\ 
  + & + & + & + & + &  &  &  &  &  &  & 10.00 & -298.53 & 617.64 & 85.07 & 0.00 \\ 
  + & + & + & + &  &  &  &  &  &  &  & 8.00 & -314.50 & 645.37 & 112.81 & 0.00 \\ 
  + & + & + &  &  &  &  &  &  &  &  & 6.00 & -342.94 & 698.10 & 165.53 & 0.00 \\ 
  + & + &  &  &  &  &  &  &  &  &  & 4.00 & -349.55 & 707.20 & 174.64 & 0.00 \\ 
   \hline
\end{tabular}
}


  \caption{Model selection table for the multinomial logistic regression models of the first morphologically based classification hypothesis. This classification hypothesis corresponds to ``morph 2'' also depicted in figures \ref{fig:roc} and \ref{fig:gen_res}. This hypothesis is based on \citet{Seeliger1945}. The column ``delta'' corresponds to the \(\Delta\)AICc values of each model, while ``weights'' correspond to the Akaike weight of that model relative to all others.}
  \label{tab:mod_sel_2}
\end{sidewaystable}

\begin{sidewaystable}
  \centering
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Sat Aug 10 22:49:43 2013
{\small
\begin{tabular}{lllllllllllrrrrr}
  \hline
(Intercept) & PC1 & PC2 & PC3 & PC4 & PC5 & PC6 & PC7 & PC8 & PC9 & PC10 & df & logLik & AICc & delta & weight \\ 
  \hline
+ & + & + & + & + & + & + & + & + & + &  & 30.00 & -303.61 & 672.34 & 0.00 & 0.77 \\ 
  + & + & + & + & + & + & + & + & + & + & + & 33.00 & -301.25 & 674.74 & 2.41 & 0.23 \\ 
  + & + & + & + & + & + & + & + & + &  &  & 27.00 & -314.28 & 686.70 & 14.36 & 0.00 \\ 
  + & + & + & + & + & + & + & + &  &  &  & 24.00 & -318.22 & 687.70 & 15.37 & 0.00 \\ 
  + & + & + & + & + & + & + &  &  &  &  & 21.00 & -335.11 & 714.71 & 42.37 & 0.00 \\ 
  + & + & + & + & + & + &  &  &  &  &  & 18.00 & -353.04 & 743.91 & 71.57 & 0.00 \\ 
  + & + & + & + & + &  &  &  &  &  &  & 15.00 & -385.20 & 801.67 & 129.34 & 0.00 \\ 
  + & + & + & + &  &  &  &  &  &  &  & 12.00 & -397.69 & 820.21 & 147.87 & 0.00 \\ 
  + & + & + &  &  &  &  &  &  &  &  & 9.00 & -437.13 & 892.73 & 220.39 & 0.00 \\ 
  + & + &  &  &  &  &  &  &  &  &  & 6.00 & -451.19 & 914.60 & 242.27 & 0.00 \\ 
   \hline
\end{tabular}
}


  \caption{Model selection table for the multinomial logistic regression models of the first morphologically based classification hypothesis. This classification hypothesis corresponds to ``molec 1'' also depicted in figures \ref{fig:roc} and \ref{fig:gen_res}. This hypothesis is based on \citet{Seeliger1945}. The column ``delta'' corresponds to the \(\Delta\)AICc values of each model, while ``weights'' correspond to the Akaike weight of that model relative to all others.}
  \label{tab:mod_sel_3}
\end{sidewaystable}

\begin{sidewaystable}
  \centering
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Sat Aug 10 22:49:43 2013
{\small
\begin{tabular}{lllllllllllrrrrr}
  \hline
(Intercept) & PC1 & PC2 & PC3 & PC4 & PC5 & PC6 & PC7 & PC8 & PC9 & PC10 & df & logLik & AICc & delta & weight \\ 
  \hline
+ & + & + & + & + & + & + & + & + & + & + & 33.00 & -251.73 & 575.67 & 0.00 & 1.00 \\ 
  + & + & + & + & + & + & + & + & + & + &  & 30.00 & -268.54 & 602.18 & 26.51 & 0.00 \\ 
  + & + & + & + & + & + & + & + & + &  &  & 27.00 & -283.99 & 626.10 & 50.43 & 0.00 \\ 
  + & + & + & + & + & + & + & + &  &  &  & 24.00 & -295.61 & 642.46 & 66.78 & 0.00 \\ 
  + & + & + & + & + & + & + &  &  &  &  & 21.00 & -302.50 & 649.48 & 73.81 & 0.00 \\ 
  + & + & + & + & + & + &  &  &  &  &  & 18.00 & -316.59 & 671.00 & 95.32 & 0.00 \\ 
  + & + & + & + & + &  &  &  &  &  &  & 15.00 & -340.84 & 712.95 & 137.27 & 0.00 \\ 
  + & + & + & + &  &  &  &  &  &  &  & 12.00 & -353.01 & 730.84 & 155.17 & 0.00 \\ 
  + & + & + &  &  &  &  &  &  &  &  & 9.00 & -378.16 & 774.78 & 199.11 & 0.00 \\ 
  + & + &  &  &  &  &  &  &  &  &  & 6.00 & -395.71 & 803.64 & 227.97 & 0.00 \\ 
   \hline
\end{tabular}
}


  \caption{Model selection table for the multinomial logistic regression models of the first morphologically based classification hypothesis. This classification hypothesis corresponds to ``molec 2'' also depicted in figures \ref{fig:roc} and \ref{fig:gen_res}. This hypothesis is based on \citet{Seeliger1945}. The column ``delta'' corresponds to the \(\Delta\)AICc values of each model, while ``weights'' correspond to the Akaike weight of that model relative to all others.}
  \label{tab:mod_sel_4}
\end{sidewaystable}

\begin{table}
  \centering
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Sat Aug 10 22:49:43 2013
\begin{tabular}{r|rrrr}
  & morph 1 & morph 2 & molec 1 & molec 2 \\ 
  \hline
morph 1 &  &  &  &  \\ 
  morph 2 & 0.00 &  &  &  \\ 
  molec 1 & 0.00 & 0.00 &  &  \\ 
  molec 2 & 0.00 & 0.00 & 0.00 &  \\ 
   \hline
\end{tabular}


  \caption{Results from pairwise Mann-Whitney U test between the AUC distributions of the generalizations of the LDA-based classification from the first 10 PCs of plastral shape. Labels correspond to those in Figure \ref{fig:gen_res}. Values of 0 correspond to p-values lower than 0.01. P-values were corrected for multiple comparison using the Holm method \citep{Holm1979}.}
  \label{tab:lda_test}
\end{table}

\begin{table}
  \centering
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Sat Aug 10 22:49:43 2013
\begin{tabular}{r|rrrr}
  & morph 1 & morph 2 & molec 1 & molec 2 \\ 
  \hline
morph 1 &  &  &  &  \\ 
  morph 2 & 0.00 &  &  &  \\ 
  molec 1 & 0.00 & 0.00 &  &  \\ 
  molec 2 & 0.00 & 0.00 & 0.00 &  \\ 
   \hline
\end{tabular}


  \caption{Results from pairwise Mann-Whitney U test between the AUC distributions of the generalizations of the multinomial logistic regression models. Labels correspond to those in Figure \ref{fig:gen_res}. Values of 0 correspond to p-values lower than 0.01. P-values were corrected for multiple comparison using the Holm method \citep{Holm1979}.}
  \label{tab:mm_test}
\end{table}

\begin{table}
  \centering
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Sat Aug 10 22:49:43 2013
\begin{tabular}{r|rrrr}
  & morph 1 & morph 2 & molec 1 & molec 2 \\ 
  \hline
morph 1 &  &  &  &  \\ 
  morph 2 & 0.00 &  &  &  \\ 
  molec 1 & 0.00 & 0.00 &  &  \\ 
  molec 2 & 0.00 & 0.00 & 0.00 &  \\ 
   \hline
\end{tabular}


  \caption{Results from pairwise Mann-Whitney U test between the AUC distributions of the generalizations of the random forest models. Labels correspond to those in Figure \ref{fig:gen_res}. Values of 0 correspond to p-values lower than 0.01. P-values were corrected for multiple comparison using the Holm method \citep{Holm1979}.}
  \label{tab:rf_test}
\end{table}


\end{document}
